{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "709c6ab4-b34e-4ca2-9fc9-40780f99e908",
   "metadata": {},
   "source": [
    "# Emotion Recognition Using Convoluted Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec29b0b-658f-4741-b8c3-96b857d11991",
   "metadata": {},
   "source": [
    "By: Aurelius Justin Lim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d02b4be-a933-4ec0-9c58-612a541a642f",
   "metadata": {},
   "source": [
    "This notebook aims to create a CNN in order to recognition human emotions. The emotions to be experimented are anger, happiness, and sadness. To do this, the network is trained from a dataset taken from kaggle. A training, test and validation set is used to ensure the correctness and optimal performance of the model. Ultimately, the model created in the notebook is integrated into an application that allows users to upload a photo and allow the model to determine the illustrated emotion. \n",
    "\n",
    "**Human Face Emotions By SANIDHYAK** \\\n",
    "**Natural Human Face Images for Emotion Recognition By Sudarshan** \\\n",
    "Reference: \\\n",
    "https://www.kaggle.com/datasets/sanidhyak/human-face-emotions?resource=download \\\n",
    "https://www.kaggle.com/datasets/sudarshanvaidya/random-images-for-face-emotion-recognition?resource=download \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27d92606-7d6f-40d5-986c-125d0c836791",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca668529-a0e3-4365-b6d6-e2935e0d7d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data successfully split into train, validation, and test sets.\n",
      "Train set: 2644 images - {'sad': 660, 'angry': 780, 'happy': 1204}\n",
      "Validation set: 331 images - {'sad': 82, 'angry': 98, 'happy': 151}\n",
      "Test set: 332 images - {'sad': 83, 'angry': 98, 'happy': 151}\n"
     ]
    }
   ],
   "source": [
    "from preprocess import preprocess\n",
    "\n",
    "command = preprocess()\n",
    "command.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f847fdb-cc51-4fac-986d-f3ad436ea2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2643 images belonging to 3 classes.\n",
      "Found 331 images belonging to 3 classes.\n",
      "Found 332 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = 'data/train'\n",
    "val_dir = 'data/val'\n",
    "test_dir = 'data/test'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c927d13-cfc1-4287-badb-08c17548c223",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fd74088-b205-4dbd-8c45-6ce7082bfa82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "82/82 [==============================] - 58s 699ms/step - loss: 1.1657 - accuracy: 0.4385 - val_loss: 1.0631 - val_accuracy: 0.4531\n",
      "Epoch 2/50\n",
      "82/82 [==============================] - 57s 699ms/step - loss: 1.0588 - accuracy: 0.4470 - val_loss: 1.0519 - val_accuracy: 0.4625\n",
      "Epoch 3/50\n",
      "82/82 [==============================] - 58s 710ms/step - loss: 1.0564 - accuracy: 0.4657 - val_loss: 1.0544 - val_accuracy: 0.4625\n",
      "Epoch 4/50\n",
      "82/82 [==============================] - 58s 704ms/step - loss: 1.0553 - accuracy: 0.4680 - val_loss: 1.0433 - val_accuracy: 0.4781\n",
      "Epoch 5/50\n",
      "82/82 [==============================] - 58s 709ms/step - loss: 1.0512 - accuracy: 0.4715 - val_loss: 1.0557 - val_accuracy: 0.4750\n",
      "Epoch 6/50\n",
      "82/82 [==============================] - 54s 659ms/step - loss: 1.0514 - accuracy: 0.4676 - val_loss: 1.0532 - val_accuracy: 0.4531\n",
      "Epoch 7/50\n",
      "82/82 [==============================] - 54s 655ms/step - loss: 1.0530 - accuracy: 0.4661 - val_loss: 1.0552 - val_accuracy: 0.4563\n",
      "Epoch 8/50\n",
      "82/82 [==============================] - 53s 650ms/step - loss: 1.0507 - accuracy: 0.4722 - val_loss: 1.0459 - val_accuracy: 0.4719\n",
      "Epoch 9/50\n",
      "82/82 [==============================] - 54s 660ms/step - loss: 1.0462 - accuracy: 0.4761 - val_loss: 1.0652 - val_accuracy: 0.4531\n",
      "Epoch 10/50\n",
      "82/82 [==============================] - 54s 652ms/step - loss: 1.0468 - accuracy: 0.4780 - val_loss: 1.0427 - val_accuracy: 0.4875\n",
      "Epoch 11/50\n",
      "82/82 [==============================] - 54s 657ms/step - loss: 1.0470 - accuracy: 0.4764 - val_loss: 1.0851 - val_accuracy: 0.4500\n",
      "Epoch 12/50\n",
      "82/82 [==============================] - 54s 656ms/step - loss: 1.0496 - accuracy: 0.4738 - val_loss: 1.0481 - val_accuracy: 0.4563\n",
      "Epoch 13/50\n",
      "82/82 [==============================] - 53s 646ms/step - loss: 1.0423 - accuracy: 0.4780 - val_loss: 1.0438 - val_accuracy: 0.4781\n",
      "Epoch 14/50\n",
      "82/82 [==============================] - 54s 660ms/step - loss: 1.0292 - accuracy: 0.4837 - val_loss: 1.0499 - val_accuracy: 0.4469\n",
      "Epoch 15/50\n",
      "82/82 [==============================] - 54s 656ms/step - loss: 1.0417 - accuracy: 0.4799 - val_loss: 1.0419 - val_accuracy: 0.4719\n",
      "Epoch 16/50\n",
      "82/82 [==============================] - 53s 651ms/step - loss: 1.0339 - accuracy: 0.4826 - val_loss: 1.0469 - val_accuracy: 0.4531\n",
      "Epoch 17/50\n",
      "82/82 [==============================] - 53s 650ms/step - loss: 1.0367 - accuracy: 0.4849 - val_loss: 1.0449 - val_accuracy: 0.4500\n",
      "Epoch 18/50\n",
      "82/82 [==============================] - 54s 655ms/step - loss: 1.0359 - accuracy: 0.4807 - val_loss: 1.0337 - val_accuracy: 0.4750\n",
      "Epoch 19/50\n",
      "82/82 [==============================] - 57s 692ms/step - loss: 1.0279 - accuracy: 0.4918 - val_loss: 1.0623 - val_accuracy: 0.4750\n",
      "Epoch 20/50\n",
      "82/82 [==============================] - 56s 686ms/step - loss: 1.0327 - accuracy: 0.4853 - val_loss: 1.0454 - val_accuracy: 0.4594\n",
      "Epoch 21/50\n",
      "82/82 [==============================] - 55s 677ms/step - loss: 1.0231 - accuracy: 0.4887 - val_loss: 1.0348 - val_accuracy: 0.4688\n",
      "Epoch 22/50\n",
      "82/82 [==============================] - 54s 659ms/step - loss: 1.0197 - accuracy: 0.4952 - val_loss: 1.0514 - val_accuracy: 0.4250\n",
      "Epoch 23/50\n",
      "82/82 [==============================] - 54s 655ms/step - loss: 1.0227 - accuracy: 0.4891 - val_loss: 1.0787 - val_accuracy: 0.4750\n",
      "Epoch 24/50\n",
      "82/82 [==============================] - 54s 663ms/step - loss: 1.0297 - accuracy: 0.4853 - val_loss: 1.0700 - val_accuracy: 0.4625\n",
      "Epoch 25/50\n",
      "82/82 [==============================] - 55s 671ms/step - loss: 1.0148 - accuracy: 0.5010 - val_loss: 1.0473 - val_accuracy: 0.4844\n",
      "Epoch 26/50\n",
      "82/82 [==============================] - 62s 749ms/step - loss: 1.0176 - accuracy: 0.4952 - val_loss: 1.0323 - val_accuracy: 0.4781\n",
      "Epoch 27/50\n",
      "82/82 [==============================] - 62s 757ms/step - loss: 1.0019 - accuracy: 0.5075 - val_loss: 1.0273 - val_accuracy: 0.4812\n",
      "Epoch 28/50\n",
      "82/82 [==============================] - 72s 883ms/step - loss: 0.9927 - accuracy: 0.5006 - val_loss: 1.0260 - val_accuracy: 0.4938\n",
      "Epoch 29/50\n",
      "82/82 [==============================] - 73s 894ms/step - loss: 0.9891 - accuracy: 0.5205 - val_loss: 1.0381 - val_accuracy: 0.4969\n",
      "Epoch 30/50\n",
      "82/82 [==============================] - 60s 725ms/step - loss: 0.9906 - accuracy: 0.5117 - val_loss: 1.0125 - val_accuracy: 0.4719\n",
      "Epoch 31/50\n",
      "82/82 [==============================] - 55s 669ms/step - loss: 0.9742 - accuracy: 0.5205 - val_loss: 1.0189 - val_accuracy: 0.4812\n",
      "Epoch 32/50\n",
      "82/82 [==============================] - 55s 674ms/step - loss: 0.9935 - accuracy: 0.5033 - val_loss: 1.0516 - val_accuracy: 0.4812\n",
      "Epoch 33/50\n",
      "82/82 [==============================] - 55s 666ms/step - loss: 0.9731 - accuracy: 0.5159 - val_loss: 1.0398 - val_accuracy: 0.4750\n",
      "Epoch 34/50\n",
      "82/82 [==============================] - 55s 674ms/step - loss: 0.9714 - accuracy: 0.5159 - val_loss: 0.9921 - val_accuracy: 0.5219\n",
      "Epoch 35/50\n",
      "82/82 [==============================] - 56s 677ms/step - loss: 0.9558 - accuracy: 0.5289 - val_loss: 0.9861 - val_accuracy: 0.5156\n",
      "Epoch 36/50\n",
      "82/82 [==============================] - 56s 687ms/step - loss: 0.9475 - accuracy: 0.5354 - val_loss: 1.0377 - val_accuracy: 0.5094\n",
      "Epoch 37/50\n",
      "82/82 [==============================] - 54s 665ms/step - loss: 0.9526 - accuracy: 0.5327 - val_loss: 0.9400 - val_accuracy: 0.5188\n",
      "Epoch 38/50\n",
      "82/82 [==============================] - 55s 664ms/step - loss: 0.9430 - accuracy: 0.5439 - val_loss: 0.9753 - val_accuracy: 0.5281\n",
      "Epoch 39/50\n",
      "82/82 [==============================] - 55s 665ms/step - loss: 0.9410 - accuracy: 0.5312 - val_loss: 0.9425 - val_accuracy: 0.5250\n",
      "Epoch 40/50\n",
      "82/82 [==============================] - 55s 670ms/step - loss: 0.9323 - accuracy: 0.5596 - val_loss: 1.0013 - val_accuracy: 0.5125\n",
      "Epoch 41/50\n",
      "82/82 [==============================] - 55s 668ms/step - loss: 0.9245 - accuracy: 0.5469 - val_loss: 0.9613 - val_accuracy: 0.5281\n",
      "Epoch 42/50\n",
      "82/82 [==============================] - 55s 672ms/step - loss: 0.9082 - accuracy: 0.5718 - val_loss: 0.9606 - val_accuracy: 0.5250\n",
      "Epoch 43/50\n",
      "82/82 [==============================] - 54s 658ms/step - loss: 0.9089 - accuracy: 0.5619 - val_loss: 0.9572 - val_accuracy: 0.5750\n",
      "Epoch 44/50\n",
      "82/82 [==============================] - 55s 666ms/step - loss: 0.8850 - accuracy: 0.5810 - val_loss: 1.0999 - val_accuracy: 0.5156\n",
      "Epoch 45/50\n",
      "82/82 [==============================] - 55s 666ms/step - loss: 0.8823 - accuracy: 0.5745 - val_loss: 0.9690 - val_accuracy: 0.5562\n",
      "Epoch 46/50\n",
      "82/82 [==============================] - 55s 670ms/step - loss: 0.8807 - accuracy: 0.5875 - val_loss: 1.0385 - val_accuracy: 0.5219\n",
      "Epoch 47/50\n",
      "82/82 [==============================] - 54s 662ms/step - loss: 0.8796 - accuracy: 0.5787 - val_loss: 1.0226 - val_accuracy: 0.5688\n",
      "Epoch 48/50\n",
      "82/82 [==============================] - 55s 670ms/step - loss: 0.8670 - accuracy: 0.5936 - val_loss: 1.0346 - val_accuracy: 0.5688\n",
      "Epoch 49/50\n",
      "82/82 [==============================] - 55s 669ms/step - loss: 0.8835 - accuracy: 0.5810 - val_loss: 0.9945 - val_accuracy: 0.5594\n",
      "Epoch 50/50\n",
      "82/82 [==============================] - 57s 697ms/step - loss: 0.8672 - accuracy: 0.5979 - val_loss: 1.0065 - val_accuracy: 0.5688\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ba5d1a8-6348-420c-b174-3b5a52d7e0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Generator Samples: 332\n",
      "Test Generator Batch Size: 32\n",
      "10/10 [==============================] - 5s 490ms/step - loss: 0.8882 - accuracy: 0.5875\n",
      "Final Test Loss: 0.8882219195365906\n",
      "Final Test Accuracy: 0.5874999761581421\n",
      "Validation Generator Samples: 331\n",
      "Validation Generator Batch Size: 32\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.9942 - accuracy: 0.5750\n",
      "Final Validation Loss: 0.994195818901062\n",
      "Final Validation Accuracy: 0.574999988079071\n"
     ]
    }
   ],
   "source": [
    "print('Test Generator Samples:', test_generator.samples)\n",
    "print('Test Generator Batch Size:', test_generator.batch_size)\n",
    "if test_generator.samples > 0 and test_generator.batch_size > 0:\n",
    "    steps = test_generator.samples // test_generator.batch_size\n",
    "    steps = max(steps, 1)  # Ensure at least one step\n",
    "else:\n",
    "    raise ValueError(\"Test generator has invalid samples or batch size.\")\n",
    "\n",
    "\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=steps)\n",
    "print('Final Test Loss:', test_loss)\n",
    "print('Final Test Accuracy:', test_acc)\n",
    "\n",
    "print('Validation Generator Samples:', validation_generator.samples)\n",
    "print('Validation Generator Batch Size:', validation_generator.batch_size)\n",
    "if validation_generator.samples > 0 and validation_generator.batch_size > 0:\n",
    "    steps = validation_generator.samples // validation_generator.batch_size\n",
    "    steps = max(steps, 1)  # Ensure at least one step\n",
    "else:\n",
    "    raise ValueError(\"Test generator has invalid samples or batch size.\")\n",
    "\n",
    "\n",
    "\n",
    "val_loss, val_acc = model.evaluate(validation_generator, steps=steps)\n",
    "print('Final Validation Loss:', val_loss)\n",
    "print('Final Validation Accuracy:', val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce6f243-4cdc-4445-9e3b-aa34adb1c412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 18 Complete [00h 04m 59s]\n",
      "val_accuracy: 0.4773413836956024\n",
      "\n",
      "Best val_accuracy So Far: 0.48036253452301025\n",
      "Total elapsed time: 01h 23m 37s\n",
      "\n",
      "Search: Running Trial #19\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "96                |32                |conv_1_filters\n",
      "3                 |3                 |conv_1_kernel_size\n",
      "192               |128               |conv_2_filters\n",
      "5                 |3                 |conv_2_kernel_size\n",
      "128               |256               |dense_units\n",
      "0.2               |0.5               |dropout_rate\n",
      "0.0034157         |0.00051529        |learning_rate\n",
      "4                 |10                |tuner/epochs\n",
      "0                 |4                 |tuner/initial_epoch\n",
      "1                 |2                 |tuner/bracket\n",
      "0                 |2                 |tuner/round\n",
      "\n",
      "Epoch 1/4\n",
      "83/83 [==============================] - 217s 3s/step - loss: 5.7208 - accuracy: 0.4344 - val_loss: 1.0776 - val_accuracy: 0.4562\n",
      "Epoch 2/4\n",
      "77/83 [==========================>...] - ETA: 14s - loss: 1.0672 - accuracy: 0.4537"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define your CNN model function\n",
    "def create_model(hp):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(\n",
    "        filters=hp.Int('conv_1_filters', min_value=32, max_value=128, step=32),\n",
    "        kernel_size=hp.Choice('conv_1_kernel_size', values=[3, 5]),\n",
    "        activation='relu',\n",
    "        input_shape=(150, 150, 3)\n",
    "    ))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(\n",
    "        filters=hp.Int('conv_2_filters', min_value=64, max_value=256, step=64),\n",
    "        kernel_size=hp.Choice('conv_2_kernel_size', values=[3, 5]),\n",
    "        activation='relu'\n",
    "    ))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "    \n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=hp.Int('dense_units', min_value=64, max_value=256, step=64),\n",
    "        activation='relu'\n",
    "    ))\n",
    "    model.add(tf.keras.layers.Dropout(rate=hp.Float('dropout_rate', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "    model.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=tf.keras.optimizers.Adam(\n",
    "            learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')\n",
    "        ),\n",
    "        metrics=['accuracy']  # Ensure this matches the objective\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create a Hyperband Tuner\n",
    "tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective='val_accuracy',  # Ensure this matches the metric used\n",
    "    max_epochs=10,\n",
    "    factor=3,\n",
    "    directory='logs',\n",
    "    project_name='cnn_model',\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "# Perform the hyperparameter search\n",
    "tuner.search(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=5\n",
    ")\n",
    "\n",
    "# Print the best hyperparameters\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(\"Best Hyperparameters:\")\n",
    "for key, value in best_hyperparameters.values.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0788e28-996d-4954-89f0-191f09143f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
