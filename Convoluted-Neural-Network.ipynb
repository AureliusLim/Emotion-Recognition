{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "709c6ab4-b34e-4ca2-9fc9-40780f99e908",
   "metadata": {},
   "source": [
    "# Emotion Recognition Using Convoluted Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec29b0b-658f-4741-b8c3-96b857d11991",
   "metadata": {},
   "source": [
    "By: Aurelius Justin Lim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d02b4be-a933-4ec0-9c58-612a541a642f",
   "metadata": {},
   "source": [
    "This notebook aims to create a CNN in order to recognition human emotions. The emotions to be experimented are anger, happiness, and sadness. To do this, the network is trained from a dataset taken from kaggle. A training, test and validation set is used to ensure the correctness and optimal performance of the model. Ultimately, the model created in the notebook is integrated into an application that allows users to upload a photo and allow the model to determine the illustrated emotion. \n",
    "\n",
    "**Human Face Emotions By SANIDHYAK**\n",
    "\n",
    "Reference: https://www.kaggle.com/datasets/sanidhyak/human-face-emotions?resource=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27d92606-7d6f-40d5-986c-125d0c836791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca668529-a0e3-4365-b6d6-e2935e0d7d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully split into train, validation, and test sets.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "\n",
    "base_dir = 'data'\n",
    "classes = ['Sad', 'Angry', 'Happy']  \n",
    "\n",
    "# Set paths for the train, validation, and test directories\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'val')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "# Create directories\n",
    "create_dir(train_dir)\n",
    "create_dir(val_dir)\n",
    "create_dir(test_dir)\n",
    "for cls in classes:\n",
    "    create_dir(os.path.join(train_dir, cls))\n",
    "    create_dir(os.path.join(val_dir, cls))\n",
    "    create_dir(os.path.join(test_dir, cls))\n",
    "\n",
    "# Split data and move files\n",
    "for cls in classes:\n",
    "    # Source directory for each class\n",
    "    src_dir = os.path.join(base_dir, cls)\n",
    "    \n",
    "    # Get a list of all files in the source directory\n",
    "    files = [os.path.join(src_dir, f) for f in os.listdir(src_dir) if os.path.isfile(os.path.join(src_dir, f))]\n",
    "    \n",
    "    # Split data: 80% train, 10% validation, 10% test\n",
    "    train_files, test_files = train_test_split(files, test_size=0.2, random_state=42)  # First, split into 80% train and 20% test\n",
    "    val_files, test_files = train_test_split(test_files, test_size=0.5, random_state=42)  # Split the 20% into two parts: 10% val, 10% test\n",
    "    \n",
    "    # Function to copy files to a target directory\n",
    "    def copy_files(files, target_dir):\n",
    "        for file in files:\n",
    "            shutil.copy(file, os.path.join(target_dir, cls))\n",
    "    \n",
    "    # Copy files to the respective directories\n",
    "    copy_files(train_files, train_dir)\n",
    "    copy_files(val_files, val_dir)\n",
    "    copy_files(test_files, test_dir)\n",
    "\n",
    "print(\"Data successfully split into train, validation, and test sets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f847fdb-cc51-4fac-986d-f3ad436ea2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 211 images belonging to 3 classes.\n",
      "Found 26 images belonging to 3 classes.\n",
      "Found 33 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = 'data/train'\n",
    "val_dir = 'data/val'\n",
    "test_dir = 'data/test'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c927d13-cfc1-4287-badb-08c17548c223",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fd74088-b205-4dbd-8c45-6ce7082bfa82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "6/6 [==============================] - 14s 2s/step - loss: 1.8833 - accuracy: 0.3073\n",
      "Epoch 2/25\n",
      "6/6 [==============================] - 9s 1s/step - loss: 1.0803 - accuracy: 0.4078\n",
      "Epoch 3/25\n",
      "6/6 [==============================] - 11s 1s/step - loss: 1.0851 - accuracy: 0.3520\n",
      "Epoch 4/25\n",
      "6/6 [==============================] - 13s 2s/step - loss: 1.0575 - accuracy: 0.3911\n",
      "Epoch 5/25\n",
      "6/6 [==============================] - 15s 3s/step - loss: 1.0044 - accuracy: 0.5052\n",
      "Epoch 6/25\n",
      "6/6 [==============================] - 13s 2s/step - loss: 0.9881 - accuracy: 0.4190\n",
      "Epoch 7/25\n",
      "6/6 [==============================] - 13s 2s/step - loss: 1.0353 - accuracy: 0.4860\n",
      "Epoch 8/25\n",
      "6/6 [==============================] - 10s 1s/step - loss: 0.9654 - accuracy: 0.5698\n",
      "Epoch 9/25\n",
      "6/6 [==============================] - 11s 2s/step - loss: 0.9154 - accuracy: 0.5475\n",
      "Epoch 10/25\n",
      "6/6 [==============================] - 12s 2s/step - loss: 0.9396 - accuracy: 0.5312\n",
      "Epoch 11/25\n",
      "6/6 [==============================] - 13s 2s/step - loss: 0.9343 - accuracy: 0.5810\n",
      "Epoch 12/25\n",
      "6/6 [==============================] - 13s 2s/step - loss: 0.9182 - accuracy: 0.5642\n",
      "Epoch 13/25\n",
      "6/6 [==============================] - 11s 2s/step - loss: 0.8490 - accuracy: 0.6313\n",
      "Epoch 14/25\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.8694 - accuracy: 0.5922\n",
      "Epoch 15/25\n",
      "6/6 [==============================] - 9s 2s/step - loss: 0.8667 - accuracy: 0.6201\n",
      "Epoch 16/25\n",
      "6/6 [==============================] - 9s 2s/step - loss: 0.8683 - accuracy: 0.6201\n",
      "Epoch 17/25\n",
      "6/6 [==============================] - 9s 1s/step - loss: 0.8309 - accuracy: 0.6369\n",
      "Epoch 18/25\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.8044 - accuracy: 0.6536\n",
      "Epoch 19/25\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.8482 - accuracy: 0.5978\n",
      "Epoch 20/25\n",
      "6/6 [==============================] - 9s 2s/step - loss: 0.8824 - accuracy: 0.5698\n",
      "Epoch 21/25\n",
      "6/6 [==============================] - 9s 2s/step - loss: 0.8996 - accuracy: 0.5625\n",
      "Epoch 22/25\n",
      "6/6 [==============================] - 9s 1s/step - loss: 0.8187 - accuracy: 0.6257\n",
      "Epoch 23/25\n",
      "6/6 [==============================] - 8s 2s/step - loss: 0.8275 - accuracy: 0.5922\n",
      "Epoch 24/25\n",
      "6/6 [==============================] - 9s 1s/step - loss: 0.8190 - accuracy: 0.5922\n",
      "Epoch 25/25\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.7690 - accuracy: 0.6816\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=25,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ba5d1a8-6348-420c-b174-3b5a52d7e0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 663ms/step - loss: 1.1621 - accuracy: 0.5625\n",
      "Test accuracy: 0.5625\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "print('Test accuracy:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
