{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "709c6ab4-b34e-4ca2-9fc9-40780f99e908",
   "metadata": {},
   "source": [
    "# Emotion Recognition Using Convoluted Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec29b0b-658f-4741-b8c3-96b857d11991",
   "metadata": {},
   "source": [
    "By: Aurelius Justin Lim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d02b4be-a933-4ec0-9c58-612a541a642f",
   "metadata": {},
   "source": [
    "This notebook aims to create a CNN in order to recognition human emotions. The emotions to be experimented are anger, happiness, and sadness. To do this, the network is trained from a dataset taken from kaggle. A training, test and validation set is used to ensure the correctness and optimal performance of the model. Ultimately, the model created in the notebook is integrated into an application that allows users to upload a photo and allow the model to determine the illustrated emotion. \n",
    "\n",
    "**Human Face Emotions By SANIDHYAK** \\\n",
    "**Natural Human Face Images for Emotion Recognition By Sudarshan** \\\n",
    "Reference: \\\n",
    "https://www.kaggle.com/datasets/sanidhyak/human-face-emotions?resource=download \\\n",
    "https://www.kaggle.com/datasets/sudarshanvaidya/random-images-for-face-emotion-recognition?resource=download \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27d92606-7d6f-40d5-986c-125d0c836791",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca668529-a0e3-4365-b6d6-e2935e0d7d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data successfully split into train, validation, and test sets.\n",
      "Train set: 2644 images - {'sad': 660, 'angry': 780, 'happy': 1204}\n",
      "Validation set: 331 images - {'sad': 82, 'angry': 98, 'happy': 151}\n",
      "Test set: 332 images - {'sad': 83, 'angry': 98, 'happy': 151}\n"
     ]
    }
   ],
   "source": [
    "from preprocess import preprocess\n",
    "\n",
    "command = preprocess()\n",
    "command.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f847fdb-cc51-4fac-986d-f3ad436ea2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2643 images belonging to 3 classes.\n",
      "Found 331 images belonging to 3 classes.\n",
      "Found 332 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = 'data/train'\n",
    "val_dir = 'data/val'\n",
    "test_dir = 'data/test'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c927d13-cfc1-4287-badb-08c17548c223",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fd74088-b205-4dbd-8c45-6ce7082bfa82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "82/82 [==============================] - 113s 1s/step - loss: 1.1760 - accuracy: 0.4416 - val_loss: 1.0645 - val_accuracy: 0.4563\n",
      "Epoch 2/50\n",
      "82/82 [==============================] - 84s 1s/step - loss: 1.0614 - accuracy: 0.4653 - val_loss: 1.0540 - val_accuracy: 0.4688\n",
      "Epoch 3/50\n",
      "82/82 [==============================] - 82s 1s/step - loss: 1.0603 - accuracy: 0.4684 - val_loss: 1.0423 - val_accuracy: 0.4875\n",
      "Epoch 4/50\n",
      "82/82 [==============================] - 77s 943ms/step - loss: 1.0537 - accuracy: 0.4730 - val_loss: 1.0504 - val_accuracy: 0.4656\n",
      "Epoch 5/50\n",
      "82/82 [==============================] - 77s 939ms/step - loss: 1.0510 - accuracy: 0.4749 - val_loss: 1.0499 - val_accuracy: 0.4625\n",
      "Epoch 6/50\n",
      "82/82 [==============================] - 85s 1s/step - loss: 1.0486 - accuracy: 0.4718 - val_loss: 1.0484 - val_accuracy: 0.4594\n",
      "Epoch 7/50\n",
      "82/82 [==============================] - 99s 1s/step - loss: 1.0579 - accuracy: 0.4734 - val_loss: 1.0597 - val_accuracy: 0.4688\n",
      "Epoch 8/50\n",
      "82/82 [==============================] - 86s 1s/step - loss: 1.0469 - accuracy: 0.4803 - val_loss: 1.0468 - val_accuracy: 0.4688\n",
      "Epoch 9/50\n",
      "82/82 [==============================] - 87s 1s/step - loss: 1.0432 - accuracy: 0.4868 - val_loss: 1.0484 - val_accuracy: 0.4625\n",
      "Epoch 10/50\n",
      "82/82 [==============================] - 86s 1s/step - loss: 1.0442 - accuracy: 0.4745 - val_loss: 1.0470 - val_accuracy: 0.4938\n",
      "Epoch 11/50\n",
      "82/82 [==============================] - 81s 987ms/step - loss: 1.0436 - accuracy: 0.4887 - val_loss: 1.0589 - val_accuracy: 0.4688\n",
      "Epoch 12/50\n",
      "82/82 [==============================] - 75s 917ms/step - loss: 1.0412 - accuracy: 0.4776 - val_loss: 1.0367 - val_accuracy: 0.4750\n",
      "Epoch 13/50\n",
      "82/82 [==============================] - 80s 972ms/step - loss: 1.0353 - accuracy: 0.4868 - val_loss: 1.0412 - val_accuracy: 0.4625\n",
      "Epoch 14/50\n",
      "82/82 [==============================] - 81s 986ms/step - loss: 1.0306 - accuracy: 0.4830 - val_loss: 1.0181 - val_accuracy: 0.4969\n",
      "Epoch 15/50\n",
      "82/82 [==============================] - 90s 1s/step - loss: 1.0312 - accuracy: 0.4822 - val_loss: 1.0307 - val_accuracy: 0.4844\n",
      "Epoch 16/50\n",
      "82/82 [==============================] - 80s 982ms/step - loss: 1.0276 - accuracy: 0.4941 - val_loss: 1.0304 - val_accuracy: 0.4563\n",
      "Epoch 17/50\n",
      "82/82 [==============================] - 82s 999ms/step - loss: 1.0275 - accuracy: 0.4849 - val_loss: 1.0292 - val_accuracy: 0.4969\n",
      "Epoch 18/50\n",
      "82/82 [==============================] - 73s 894ms/step - loss: 1.0236 - accuracy: 0.4833 - val_loss: 1.0350 - val_accuracy: 0.4594\n",
      "Epoch 19/50\n",
      "82/82 [==============================] - 80s 969ms/step - loss: 1.0230 - accuracy: 0.4883 - val_loss: 1.0317 - val_accuracy: 0.4969\n",
      "Epoch 20/50\n",
      "82/82 [==============================] - 79s 967ms/step - loss: 1.0145 - accuracy: 0.4952 - val_loss: 1.0123 - val_accuracy: 0.5031\n",
      "Epoch 21/50\n",
      "82/82 [==============================] - 79s 969ms/step - loss: 1.0146 - accuracy: 0.4933 - val_loss: 0.9914 - val_accuracy: 0.4938\n",
      "Epoch 22/50\n",
      "82/82 [==============================] - 85s 1s/step - loss: 1.0095 - accuracy: 0.4960 - val_loss: 1.0167 - val_accuracy: 0.4844\n",
      "Epoch 23/50\n",
      "82/82 [==============================] - 85s 1s/step - loss: 1.0044 - accuracy: 0.5082 - val_loss: 0.9919 - val_accuracy: 0.5063\n",
      "Epoch 24/50\n",
      "82/82 [==============================] - 79s 964ms/step - loss: 0.9955 - accuracy: 0.5067 - val_loss: 1.0132 - val_accuracy: 0.5000\n",
      "Epoch 25/50\n",
      "82/82 [==============================] - 80s 971ms/step - loss: 0.9978 - accuracy: 0.5052 - val_loss: 0.9681 - val_accuracy: 0.5188\n",
      "Epoch 26/50\n",
      "82/82 [==============================] - 81s 983ms/step - loss: 0.9887 - accuracy: 0.5117 - val_loss: 0.9937 - val_accuracy: 0.5063\n",
      "Epoch 27/50\n",
      "82/82 [==============================] - 79s 959ms/step - loss: 0.9878 - accuracy: 0.5186 - val_loss: 0.9607 - val_accuracy: 0.5406\n",
      "Epoch 28/50\n",
      "82/82 [==============================] - 78s 951ms/step - loss: 0.9720 - accuracy: 0.5293 - val_loss: 0.9675 - val_accuracy: 0.5344\n",
      "Epoch 29/50\n",
      "82/82 [==============================] - 83s 1s/step - loss: 0.9835 - accuracy: 0.5163 - val_loss: 0.9805 - val_accuracy: 0.5312\n",
      "Epoch 30/50\n",
      "82/82 [==============================] - 79s 966ms/step - loss: 0.9617 - accuracy: 0.5320 - val_loss: 0.9929 - val_accuracy: 0.5281\n",
      "Epoch 31/50\n",
      "82/82 [==============================] - 79s 962ms/step - loss: 0.9918 - accuracy: 0.5163 - val_loss: 0.9916 - val_accuracy: 0.5281\n",
      "Epoch 32/50\n",
      "82/82 [==============================] - 80s 977ms/step - loss: 0.9648 - accuracy: 0.5408 - val_loss: 0.9853 - val_accuracy: 0.5469\n",
      "Epoch 33/50\n",
      "82/82 [==============================] - 80s 971ms/step - loss: 0.9477 - accuracy: 0.5477 - val_loss: 0.9491 - val_accuracy: 0.5406\n",
      "Epoch 34/50\n",
      "82/82 [==============================] - 80s 944ms/step - loss: 0.9483 - accuracy: 0.5462 - val_loss: 0.9578 - val_accuracy: 0.5531\n",
      "Epoch 35/50\n",
      "82/82 [==============================] - 78s 950ms/step - loss: 0.9381 - accuracy: 0.5473 - val_loss: 0.9277 - val_accuracy: 0.5531\n",
      "Epoch 36/50\n",
      "82/82 [==============================] - 79s 969ms/step - loss: 0.9327 - accuracy: 0.5439 - val_loss: 0.9103 - val_accuracy: 0.5844\n",
      "Epoch 37/50\n",
      "82/82 [==============================] - 81s 991ms/step - loss: 0.9405 - accuracy: 0.5492 - val_loss: 0.9832 - val_accuracy: 0.5375\n",
      "Epoch 38/50\n",
      "82/82 [==============================] - 81s 991ms/step - loss: 0.9243 - accuracy: 0.5576 - val_loss: 0.9129 - val_accuracy: 0.5625\n",
      "Epoch 39/50\n",
      "82/82 [==============================] - 81s 982ms/step - loss: 0.9183 - accuracy: 0.5676 - val_loss: 0.9085 - val_accuracy: 0.5688\n",
      "Epoch 40/50\n",
      "82/82 [==============================] - 83s 1s/step - loss: 0.8960 - accuracy: 0.5791 - val_loss: 0.9205 - val_accuracy: 0.5750\n",
      "Epoch 41/50\n",
      "82/82 [==============================] - 82s 990ms/step - loss: 0.9054 - accuracy: 0.5695 - val_loss: 0.9167 - val_accuracy: 0.5469\n",
      "Epoch 42/50\n",
      "82/82 [==============================] - 80s 973ms/step - loss: 0.9026 - accuracy: 0.5749 - val_loss: 0.9097 - val_accuracy: 0.5750\n",
      "Epoch 43/50\n",
      "82/82 [==============================] - 79s 964ms/step - loss: 0.9127 - accuracy: 0.5634 - val_loss: 0.9650 - val_accuracy: 0.5469\n",
      "Epoch 44/50\n",
      "82/82 [==============================] - 80s 978ms/step - loss: 0.9006 - accuracy: 0.5741 - val_loss: 1.0071 - val_accuracy: 0.5594\n",
      "Epoch 45/50\n",
      "82/82 [==============================] - 80s 971ms/step - loss: 0.8914 - accuracy: 0.5837 - val_loss: 0.9059 - val_accuracy: 0.5969\n",
      "Epoch 46/50\n",
      "82/82 [==============================] - 73s 888ms/step - loss: 0.8707 - accuracy: 0.5990 - val_loss: 0.9245 - val_accuracy: 0.5656\n",
      "Epoch 47/50\n",
      "82/82 [==============================] - 84s 1s/step - loss: 0.8847 - accuracy: 0.5818 - val_loss: 0.8765 - val_accuracy: 0.5844\n",
      "Epoch 48/50\n",
      "82/82 [==============================] - 78s 956ms/step - loss: 0.8554 - accuracy: 0.6028 - val_loss: 0.9239 - val_accuracy: 0.5719\n",
      "Epoch 49/50\n",
      "82/82 [==============================] - 78s 943ms/step - loss: 0.8783 - accuracy: 0.5864 - val_loss: 0.8989 - val_accuracy: 0.5531\n",
      "Epoch 50/50\n",
      "82/82 [==============================] - 79s 965ms/step - loss: 0.8561 - accuracy: 0.6036 - val_loss: 0.8690 - val_accuracy: 0.5781\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ba5d1a8-6348-420c-b174-3b5a52d7e0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Generator Samples: 332\n",
      "Test Generator Batch Size: 32\n",
      "10/10 [==============================] - 7s 779ms/step - loss: 0.8216 - accuracy: 0.6406\n",
      "Final Test Loss: 0.8215895891189575\n",
      "Final Test Accuracy: 0.640625\n",
      "Validation Generator Samples: 331\n",
      "Validation Generator Batch Size: 32\n",
      "10/10 [==============================] - 5s 472ms/step - loss: 0.8547 - accuracy: 0.5875\n",
      "Final Validation Loss: 0.8546947240829468\n",
      "Final Validation Accuracy: 0.5874999761581421\n"
     ]
    }
   ],
   "source": [
    "print('Test Generator Samples:', test_generator.samples)\n",
    "print('Test Generator Batch Size:', test_generator.batch_size)\n",
    "if test_generator.samples > 0 and test_generator.batch_size > 0:\n",
    "    steps = test_generator.samples // test_generator.batch_size\n",
    "    steps = max(steps, 1)  # Ensure at least one step\n",
    "else:\n",
    "    raise ValueError(\"Test generator has invalid samples or batch size.\")\n",
    "\n",
    "\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=steps)\n",
    "print('Final Test Loss:', test_loss)\n",
    "print('Final Test Accuracy:', test_acc)\n",
    "\n",
    "print('Validation Generator Samples:', validation_generator.samples)\n",
    "print('Validation Generator Batch Size:', validation_generator.batch_size)\n",
    "if validation_generator.samples > 0 and validation_generator.batch_size > 0:\n",
    "    steps = validation_generator.samples // validation_generator.batch_size\n",
    "    steps = max(steps, 1)  # Ensure at least one step\n",
    "else:\n",
    "    raise ValueError(\"Test generator has invalid samples or batch size.\")\n",
    "\n",
    "\n",
    "\n",
    "val_loss, val_acc = model.evaluate(validation_generator, steps=steps)\n",
    "print('Final Validation Loss:', val_loss)\n",
    "print('Final Validation Accuracy:', val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ce6f243-4cdc-4445-9e3b-aa34adb1c412",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Define your CNN model function\n",
    "# def create_model(hp):\n",
    "#     model = tf.keras.models.Sequential()\n",
    "    \n",
    "#     # First Conv2D layer\n",
    "#     model.add(tf.keras.layers.Conv2D(\n",
    "#         filters=hp.Int('conv_1_filters', min_value=32, max_value=128, step=32),\n",
    "#         kernel_size=hp.Choice('conv_1_kernel_size', values=[3, 5]),\n",
    "#         activation='relu',\n",
    "#         input_shape=(150, 150, 3)\n",
    "#     ))\n",
    "#     model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "\n",
    "#     # Second Conv2D layer\n",
    "#     model.add(tf.keras.layers.Conv2D(\n",
    "#         filters=hp.Int('conv_2_filters', min_value=64, max_value=256, step=64),\n",
    "#         kernel_size=hp.Choice('conv_2_kernel_size', values=[3, 5]),\n",
    "#         activation='relu'\n",
    "#     ))\n",
    "#     model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "\n",
    "#     # Third Conv2D layer to match the original model structure\n",
    "#     model.add(tf.keras.layers.Conv2D(\n",
    "#         filters=hp.Int('conv_3_filters', min_value=128, max_value=512, step=128),\n",
    "#         kernel_size=hp.Choice('conv_3_kernel_size', values=[3, 5]),\n",
    "#         activation='relu'\n",
    "#     ))\n",
    "#     model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "\n",
    "#     # Fully connected layers\n",
    "#     model.add(tf.keras.layers.Flatten())\n",
    "#     model.add(tf.keras.layers.Dense(\n",
    "#         units=hp.Int('dense_units', min_value=64, max_value=512, step=64),  # Adjusted range for more flexibility\n",
    "#         activation='relu'\n",
    "#     ))\n",
    "#     model.add(tf.keras.layers.Dropout(rate=hp.Float('dropout_rate', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "#     model.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "#     # Compile the model\n",
    "#     model.compile(\n",
    "#         loss='categorical_crossentropy',\n",
    "#         optimizer=tf.keras.optimizers.Adam(\n",
    "#             learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')\n",
    "#         ),\n",
    "#         metrics=['accuracy']\n",
    "#     )\n",
    "\n",
    "#     return model\n",
    "\n",
    "# # Create a Hyperband Tuner\n",
    "# tuner = kt.Hyperband(\n",
    "#     create_model,\n",
    "#     objective='val_accuracy',  # Ensure this matches the metric used\n",
    "#     max_epochs=10,\n",
    "#     factor=3,\n",
    "#     directory='logs',\n",
    "#     project_name='cnn_model',\n",
    "#     overwrite=True\n",
    "# )\n",
    "\n",
    "# # Perform the hyperparameter search\n",
    "# tuner.search(\n",
    "#     train_generator,\n",
    "#     validation_data=validation_generator,\n",
    "#     epochs=5\n",
    "# )\n",
    "\n",
    "# # Print the best hyperparameters\n",
    "# best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "# print(\"Best Hyperparameters:\")\n",
    "# for key, value in best_hyperparameters.values.items():\n",
    "#     print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0788e28-996d-4954-89f0-191f09143f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential([\n",
    "#     # First Conv2D layer with tuned filters and kernel size\n",
    "#     Conv2D(128, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "#     MaxPooling2D(2, 2),\n",
    "    \n",
    "#     # Second Conv2D layer with tuned filters and kernel size\n",
    "#     Conv2D(128, (3, 3), activation='relu'),\n",
    "#     MaxPooling2D(2, 2),\n",
    "    \n",
    "#     # Third Conv2D layer with tuned filters and kernel size\n",
    "#     Conv2D(512, (3, 3), activation='relu'),\n",
    "#     MaxPooling2D(2, 2),\n",
    "    \n",
    "#     # Flatten layer\n",
    "#     Flatten(),\n",
    "    \n",
    "#     # Dense layer with tuned units\n",
    "#     Dense(128, activation='relu'),\n",
    "    \n",
    "#     # Dropout layer with tuned dropout rate\n",
    "#     Dropout(0.1),\n",
    "    \n",
    "#     # Output layer\n",
    "#     Dense(3, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# # Compile the model with tuned learning rate\n",
    "# model.compile(\n",
    "#     optimizer=Adam(learning_rate=0.00042232),  # Best learning rate\n",
    "#     loss='categorical_crossentropy',\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# # Fit the model using the tuned epochs\n",
    "# history = model.fit(\n",
    "#     train_generator,\n",
    "#     steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "#     epochs=50,  # Best number of epochs\n",
    "#     validation_data=validation_generator,\n",
    "#     validation_steps=validation_generator.samples // validation_generator.batch_size\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebca0b51-b506-4a2a-ac9d-6c3072517e8e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model.save('ml-model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b8ad42f-03d3-438b-b476-9b8c09e96063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'angry': 0, 'happy': 1, 'sad': 2}\n"
     ]
    }
   ],
   "source": [
    "print(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d2024a-9f02-4e0f-8171-8e7f17cb82e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
